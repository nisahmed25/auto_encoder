{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from alpha import iterate_minibatches \n",
    "from alpha import make_square\n",
    "from cnn_utils import conv_layer,fc_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, math\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tqdm as tqdm\n",
    "import os,cv2,random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.0'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data = 99\n",
    "IMG_SIZE = 64\n",
    "labels = []\n",
    "data = []\n",
    "DIR = \"./train\"\n",
    "for i, im in enumerate(os.listdir(DIR)):\n",
    "  if not im.startswith('.'):\n",
    "    path = os.path.join(DIR, im)\n",
    "    if i >= num_data : break\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
    "    img = img/255.0\n",
    "    data.append([np.array(img)])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.array(data).reshape(-1,IMG_SIZE,IMG_SIZE,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99, 64, 64, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('./train.npy', train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.load('./train.npy').reshape(99, 64, 64, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 15401533137564674239]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def saveGraph(graph):\n",
    "  with tf.Session(graph = graph) as sess:\n",
    "    filename = \"./summary_log/VS-\"+time.strftime(\"%H%M%S\")\n",
    "    writer = tf.summary.FileWriter(filename, sess.graph)\n",
    "  print(\"Tensorboard summary saved to \"+filename) midhun pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph1 = tf.Graph()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with graph1.as_default():\n",
    "    X = tf.placeholder(tf.float32,[None,64,64,3])\n",
    "    Y = tf.placeholder(tf.float32,[None,64,64,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lrelu(b,alpha=0.1):\n",
    "    return tf.maximum(alpha*b,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Encoder\n",
    "\n",
    "with graph1.as_default():\n",
    "  with tf.name_scope('en-convolutions'):\n",
    "    conv0 = tf.layers.conv2d(X, filters = 4, kernel_size  = (3, 3), strides = (1,1), padding = 'SAME', use_bias = True, activation = lrelu, name = 'conv0')\n",
    "  # 32*32*4\n",
    "  with tf.name_scope('en_pooling') :\n",
    "    maxpool0 = tf.layers.max_pooling2d(conv0, pool_size = (2, 2), strides = (2, 2),name = 'pool0')\n",
    "    \n",
    "  with tf.name_scope('en-convolutions'):\n",
    "    conv1 = tf.layers.conv2d(maxpool0, filters = 4, kernel_size  = (3, 3), strides = (1,1), padding = 'SAME', use_bias = True, activation = lrelu, name = 'conv1')\n",
    "  \n",
    "  # 32*32*4\n",
    "  with tf.name_scope('en_pooling') :\n",
    "    maxpool1 = tf.layers.max_pooling2d(conv1, pool_size = (2, 2), strides = (2, 2),name = 'pool0')\n",
    "  # 16*16*4 \n",
    "  with tf.name_scope('en-convolutions'):\n",
    "    conv2 = tf.layers.conv2d(maxpool1, filters = 8, kernel_size  = (3, 3), strides = (1,1), padding = 'SAME', use_bias = True, activation = lrelu, name = 'conv2')\n",
    "  # 16*16*8\n",
    "  with tf.name_scope('en_pooling') :\n",
    "    maxpool2 = tf.layers.max_pooling2d(conv2, pool_size = (2, 2), strides = (2, 2),name = 'pool0')\n",
    "  # 8*8*8\n",
    "  with tf.name_scope('en-convolutions'):\n",
    "    conv3 = tf.layers.conv2d(maxpool2, filters = 16, kernel_size  = (3, 3), strides = (1,1), padding = 'SAME', use_bias = True, activation = lrelu, name = 'conv3')\n",
    "  #  8x8x16\n",
    "  with tf.name_scope('encoding'):\n",
    "    encoded = tf.layers.average_pooling2d(conv3,pool_size=(2,2),strides=(2,2),name='encoding')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### decoder\n",
    "\n",
    "with graph1.as_default():\n",
    "  with tf.name_scope('decoder'):\n",
    "    upsample1 = tf.layers.conv2d_transpose(encoded, filters = 16, kernel_size = 3, padding = 'SAME', strides = 2, name = 'upsample1')\n",
    "    # 8*8*16\n",
    "    conv4 = tf.layers.conv2d(upsample1, filters = 16, kernel_size = (3,3), strides = (1,1), padding = 'SAME', use_bias = True, name = 'conv4',activation =lrelu)\n",
    "    # 8x8x16\n",
    "    upsample2 = tf.layers.conv2d_transpose(conv4,filters=8,kernel_size=3,padding='same',strides=2,name='upsample2')\n",
    "    # 16x16x8\n",
    "    conv5 = tf.layers.conv2d(upsample2,filters=8,kernel_size=(3,3),strides=(1,1),name='conv5',padding='SAME',use_bias=True,activation=lrelu)\n",
    "    # 16x16x8\n",
    "    upsample3 = tf.layers.conv2d_transpose(conv5,filters=8,kernel_size=5,padding='same',strides=2,name='upsample3')\n",
    "    # 32x32x8\n",
    "    conv6 = tf.layers.conv2d(upsample3,filters=4,kernel_size=(5,5),strides=(1,1),name='conv6',padding='SAME',use_bias=True,activation=lrelu)\n",
    "        \n",
    "    # 16x16x8\n",
    "    upsample4 = tf.layers.conv2d_transpose(conv6,filters=8,kernel_size=5,padding='same',strides=2,name='upsample4')\n",
    "    # 32x32x8\n",
    "    conv7 = tf.layers.conv2d(upsample4,filters=4,kernel_size=(5,5),strides=(1,1),name='conv7',padding='SAME',use_bias=True,activation=lrelu)\n",
    "        \n",
    "        \n",
    "    # 32x32x4\n",
    "    logits = tf.layers.conv2d(conv7,filters=3,kernel_size=(3,3),strides=(1,1),name='logits',padding='SAME',use_bias=True)\n",
    "    #Now 32x32x3midhun pk\n",
    "    # Pass logits through sigmoid to get reconstructed image\n",
    "    decoded = tf.sigmoid(logits,name='recon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorboard summary saved to ./summary_log/VS-114909\n"
     ]
    }
   ],
   "source": [
    "saveGraph(graph1)midhun pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with graph1.as_default():\n",
    "  loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=Y)\n",
    "  lr = tf.placeholder(tf.float32, shape=[])\n",
    "  cost = tf.reduce_mean(loss) \n",
    "  opt = tf.train.AdamOptimizer(learning_rate=lr).minimize(cost) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./saved_model/model\n",
      "Epoch: 1/20... Training loss: 0.4881\n",
      "Epoch: 2/20... Training loss: 0.4869\n",
      "Epoch: 3/20... Training loss: 0.4857\n",
      "Epoch: 4/20... Training loss: 0.4845\n",
      "Epoch: 5/20... Training loss: 0.4833\n",
      "Epoch: 6/20... Training loss: 0.4824\n",
      "Epoch: 7/20... Training loss: 0.4814\n",
      "Epoch: 8/20... Training loss: 0.4805\n",
      "Epoch: 9/20... Training loss: 0.4798\n",
      "Epoch: 10/20... Training loss: 0.4791\n",
      "Epoch: 11/20... Training loss: 0.4784\n",
      "Epoch: 12/20... Training loss: 0.4777\n",
      "Epoch: 13/20... Training loss: 0.4769\n",
      "Epoch: 14/20... Training loss: 0.4760\n",
      "Epoch: 15/20... Training loss: 0.4751\n",
      "Epoch: 16/20... Training loss: 0.4741\n",
      "Epoch: 17/20... Training loss: 0.4732\n",
      "Epoch: 18/20... Training loss: 0.4723\n",
      "Epoch: 19/20... Training loss: 0.4714\n",
      "Epoch: 20/20... Training loss: 0.4705\n"
     ]
    }
   ],
   "source": [
    "minibatch_size = 256\n",
    "epoch = 20\n",
    "learning_rate = 0.0005\n",
    "\n",
    "\n",
    "with tf.Session(graph=graph1) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('./saved_model/'))\n",
    "    for ep in range(epoch):\n",
    "      avg_cost = 0\n",
    "      for i, minibatch in enumerate(iterate_minibatches(train, minibatch_size)):\n",
    "        batch_cost, _ = sess.run([cost, opt], feed_dict={X: minibatch,\n",
    "                                                             Y: minibatch,\n",
    "                                                            lr: learning_rate})\n",
    "        \n",
    "      print(\"Epoch: {}/{}...\".format(ep+1, epoch), \\\n",
    "                  \"Training loss: {:.4f}\".format(batch_cost))\n",
    "    saver.save(sess, \"./saved_model/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./saved_model/model\n"
     ]
    }
   ],
   "source": [
    "limit = 9999\n",
    "DIR = './train'\n",
    "IMG_SIZE = 64\n",
    "embeddings = []\n",
    "labels = []\n",
    "with tf.Session(graph=graph1) as sess:\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('./saved_model/'))\n",
    "    for i, im in enumerate(os.listdir(DIR)):    \n",
    "        if not im.startswith('.'):\n",
    "            path = os.path.join(DIR, im)\n",
    "            if i >= limit: break\n",
    "            img = cv2.imread(path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
    "            img = img/255.0\n",
    "            embeddings.append(sess.run(encoded,feed_dict={X:img.reshape((-1,64,64,3))}).reshape(-1,256))\n",
    "            labels.append(int(path.split('.')[-2].split('-')[-1]))\n",
    "labels = np.array(labels)\n",
    "embeddings = np.array(np.squeeze(embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving npy for future usage\n",
    "np.save('./embeddings.npy', embeddings)\n",
    "np.save('./labels.npy', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.load('./embeddings.npy').reshape(5000, 256) \n",
    "labels = np.load('./labels.npy').reshape(5000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(embeddings)\n",
    "data['labels'] = labels\n",
    "data.set_index('labels', inplace=True)\n",
    "data.sort_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./data.npy', embeddings)\n",
    "data = np.load('./data.npy').reshape(5000, 256)\n",
    "data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = pd.read_csv('./Data/data.csv')\n",
    "tunicSlice = pd.read_csv('./Data/tunics.csv')\n",
    "\n",
    "def getinfo(idx):\n",
    "  pid = Data[Data.index==idx]['productId'].values[0]\n",
    "  idxTunic = tunicSlice[tunicSlice.productId==pid]['index'].values[0]\n",
    "  return idxTunic, tunicSlice.loc[idxTunic]['sellerName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTestimage(idx):\n",
    "  \n",
    "  from PIL import Image\n",
    "  img = path = './train/im-400-{}.jpg'.format(idx)\n",
    "  img = Image.open(path)\n",
    "  img = make_square(img)\n",
    "  img = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
    "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "  return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEmbeddings(idx):\n",
    "  \n",
    "  img = IMG_SIZE = 64\n",
    "  img = cv2.imread('./train/im-400-{}.jpg'.format(idx))\n",
    "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "  img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
    "  img = img/255.0\n",
    "  \n",
    "  with tf.Session(graph=graph1) as sess:\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('./saved_model/'))\n",
    "    dist = sess.run(encoded,feed_dict={X:img.reshape((-1,64,64,3))})\n",
    "    \n",
    "  return np.squeeze(dist.reshape(-1,4*4*16))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./saved_model/model\n",
      "[ 0.31782973 -0.01172512  0.17890753 -0.04678841  0.48739654  0.10384879\n",
      "  0.25308782  0.46912694  0.47205538 -0.06895326  0.15418787  0.04846708\n",
      " -0.07288961 -0.01407217 -0.02208111  0.16211846  0.35695687 -0.01479566\n",
      "  0.14447856 -0.02823993  0.36247307  0.03484306  0.22247162  0.26179254\n",
      "  0.4566845  -0.04280451  0.04151934  0.10462055 -0.06762135 -0.00361139\n",
      " -0.01558663  0.22934838  0.30016872 -0.01910256  0.11116482 -0.04157083\n",
      "  0.46055123  0.05664933  0.21092622  0.4214196   0.4343406  -0.05453917\n",
      "  0.11362436  0.01554032 -0.07284284 -0.01475112 -0.02215968  0.21870632\n",
      "  0.31301776 -0.01696425  0.23367606 -0.04322098  0.44799134  0.07404392\n",
      "  0.40627357  0.5303667   0.59851325 -0.05248134  0.05909903  0.04067545\n",
      " -0.05752292 -0.01961535 -0.02448858  0.08952505  0.17008445 -0.02305754\n",
      "  0.21171992 -0.04065169  0.31459963 -0.04194951  0.14529046  0.3243929\n",
      "  0.3437604  -0.05206476  0.02951137  0.05871679 -0.05638153 -0.00576182\n",
      " -0.02388948  0.2940953   0.24865524 -0.01604732  0.10989618 -0.02581195\n",
      "  0.23577607 -0.040779    0.06425518  0.11679723  0.29102597 -0.03863787\n",
      " -0.01488296  0.1083879  -0.05046553  0.00327891 -0.0196991   0.34435982\n",
      "  0.28930917 -0.01835048  0.11159447 -0.02574786  0.2491962  -0.03853715\n",
      "  0.00482684  0.08835103  0.26509044 -0.03930251 -0.0138592   0.10448457\n",
      " -0.0599483  -0.00314271 -0.02156498  0.42331618  0.26430267 -0.02454343\n",
      "  0.24345315 -0.03717006  0.3220536  -0.03545304  0.18525735  0.23004627\n",
      "  0.4094574  -0.03401056 -0.00670993  0.03229091 -0.05682806 -0.01247174\n",
      " -0.02603282  0.37996772  0.2274622  -0.01942512  0.17578612 -0.03526365\n",
      "  0.30855402 -0.02866351  0.1366192   0.20915419  0.31051505 -0.04517289\n",
      "  0.03063427  0.03355835 -0.05358926 -0.00958029 -0.02404557  0.33096606\n",
      "  0.24711025 -0.01902447  0.06525959 -0.02264112  0.2589899  -0.02508909\n",
      "  0.11661902  0.11642699  0.27429846 -0.03078116 -0.00805012  0.07422735\n",
      " -0.04721214 -0.00138591 -0.01411321  0.32273847  0.25390065 -0.01787063\n",
      "  0.05969633 -0.02408224  0.26829958 -0.03345239  0.02598887  0.12464175\n",
      "  0.2592218  -0.0398067  -0.01080736  0.07602322 -0.05754703  0.00069454\n",
      " -0.017233    0.31268936  0.21908566 -0.0248967   0.19781438 -0.03955693\n",
      "  0.38232148 -0.02925288  0.21021242  0.29516274  0.43795824 -0.04175301\n",
      "  0.01203316  0.00468967 -0.06354783 -0.01493041 -0.02579284  0.36351037\n",
      "  0.24254808 -0.02048119  0.15386762 -0.03373368  0.3546493  -0.0319997\n",
      "  0.14236087  0.35347262  0.37590754 -0.05881187  0.02779239  0.11044368\n",
      " -0.07255968  0.01755377 -0.01852537  0.25634077  0.23933977 -0.00726048\n",
      "  0.23002565 -0.01600411  0.23190945 -0.0304679   0.19444512  0.15815902\n",
      "  0.31100345 -0.02909117 -0.02209252  0.14247474 -0.04455814 -0.00071956\n",
      " -0.01796182  0.22627571  0.2497408  -0.01537033  0.00188542 -0.01645592\n",
      "  0.17380704 -0.03223508 -0.00987341  0.06818242  0.15801284 -0.03132069\n",
      " -0.01239413  0.15231875 -0.05108709  0.07770574 -0.01526697  0.26864713\n",
      "  0.1620344  -0.02257402  0.25127637 -0.03633928  0.40814444 -0.03460151\n",
      "  0.21486779  0.3822931   0.44570422 -0.04892323  0.01719569  0.06208388\n",
      " -0.06668821 -0.0135857  -0.02676576  0.27485013]\n"
     ]
    }
   ],
   "source": [
    "img = IMG_SIZE = 64\n",
    "img = cv2.imread('./train/im-400-{}.jpg'.format(1))\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
    "img = img/255.0\n",
    "\n",
    "with tf.Session(graph=graph1) as sess:\n",
    "  saver = tf.train.Saver()\n",
    "  saver.restore(sess, tf.train.latest_checkpoint('./saved_model/'))\n",
    "  dist = sess.run(encoded,feed_dict={X:img.reshape((-1,64,64,3))})\n",
    "  x = np.squeeze(dist.reshape(-1,256))\n",
    "  print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredictedImages(score):\n",
    "  images = []\n",
    "  IMG_SIZE = 200\n",
    "  \n",
    "  for idx in score.index:\n",
    "    path = './train/im-400-{}.jpg'.format(1)\n",
    "    img = Image.open(path)\n",
    "    img  = make_square(img)\n",
    "    img = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
    "    images.append([np.array(img)])\n",
    "  return np.array(images).reshape(-1, 200,200,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredictions(testEmbeddings):\n",
    "  dist = (np.array(data) - testEmbeddings)**2\n",
    "  dist = np.sum(dist, axis=1)\n",
    "  dist = np.sqrt(dist)\n",
    "  \n",
    "  df = pd.DataFrame({'distance':dist})\n",
    "  df.index = data.index\n",
    "  df.sort_values('distance', ascending=True, inplace=True)\n",
    "  score = df[:20]\n",
    "  score['score'] = df.distance[:20].apply(lambda x: np.round(1-np.tanh(x)**10, 30)).values\n",
    "  return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotImages(idx, im, images, score):\n",
    "  fig, axes = plt.subplots(5,2, figsize = (15,25))\n",
    "  fig.subplots_adjust(hspace = 0.3, wspace = 0.3)\n",
    "  for i, ax in enumerate(axes.flat):\n",
    "    if i==0:\n",
    "      idX, sellerName = getinfo(idx)\n",
    "      ax.imshow(im, cmap = 'binary')\n",
    "      xlabel = \"Original image \\n id: {} \\n Seller: {}\".format(idx, sellerName)\n",
    "      ax.set_xlabel(xlabel, fontsize = 13)\n",
    "    else:\n",
    "      ax.imshow(images[i-1], cmap = 'binary')\n",
    "      idX, sellerName = getinfo(score.index[i])\n",
    "      xlabel = \"score: {} \\nid:{} \\n Seller: {}\".format(score.score.iloc[i-1], idX, sellerName)\n",
    "      ax.set_xlabel(xlabel, fontsize = 12)\n",
    "      #Remove axis ticks\n",
    "      ax.set_xticks([])\n",
    "      ax.set_yticks([])\n",
    "      \n",
    "      \n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./saved_model/model\n",
      "INFO:tensorflow:Restoring parameters from ./saved_model/model\n"
     ]
    }
   ],
   "source": [
    "sc = []\n",
    "for i in range(2):\n",
    "  testEmbeddings = getEmbeddings(1)\n",
    "  score = getPredictions(testEmbeddings)\n",
    "  ls = [[score.index[i], score.score.iloc[i]] for i in range(20) if score.score.iloc[i]>0.89]\n",
    "  ind, _ = getinfo(i)\n",
    "  out[str(ind)] = ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./saved_model/model\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-124-504338f1c8e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1993\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestEmbeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetEmbeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetPredictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestEmbeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplotImages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "idx = 1993\n",
    "im, testEmbeddings = getEmbeddings(idx)\n",
    "images, score = getPredictions(testEmbeddings)\n",
    "plotImages(idx, im, images, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
